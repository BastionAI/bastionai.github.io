<style>
.transformer-container {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    border: 1px solid #ddd;
    border-radius: 8px;
    padding: 20px;
    margin: 2em 0;
    text-align: center;
    background-color: #f9f9f9;
}

.transformer-block {
    display: flex;
    flex-direction: column;
    align-items: center;
    position: relative;
}

.transformer-component {
    border: 2px solid #ccc;
    border-radius: 8px;
    padding: 15px 25px;
    margin: 15px 0;
    width: 250px;
    background-color: white;
    position: relative;
    cursor: pointer;
    transition: all 0.2s ease-in-out;
}

.transformer-component:hover {
    border-color: #007aff;
    transform: scale(1.03);
    box-shadow: 0 4px 15px rgba(0,0,0,0.1);
}

.transformer-component h4 {
    margin: 0;
    color: #333;
}

.popup {
    display: none;
    position: absolute;
    left: 105%;
    top: 0;
    width: 280px;
    border: 1px solid #ccc;
    border-radius: 8px;
    background-color: #fff;
    padding: 15px;
    box-shadow: 0 5px 15px rgba(0,0,0,0.15);
    text-align: left;
    z-index: 100;
    font-size: 0.9em;
    line-height: 1.5;
}

.transformer-component:hover .popup {
    display: block;
}

.arrow {
    font-size: 24px;
    color: #888;
    margin: -10px 0;
}
</style>

<div class="transformer-container">
    <p><strong>Interactive Transformer Block</strong><br/>Hover over each component to learn more.</p>
    <div class="transformer-block">

        <div class="transformer-component" id="input">
            <h4>Input Embeddings</h4>
            <div class="popup">
                <strong>Input:</strong> The process starts with the token embeddings we discussed in Part 1. These are the numerical representations of your text, rich with semantic meaning.
            </div>
        </div>

        <div class="arrow">↓</div>

        <div class="transformer-component" id="mha">
            <h4>Multi-Head Self-Attention</h4>
            <div class="popup">
                <strong>The "Cocktail Party":</strong> This is where every word looks at every other word to find out which ones are most important for its own meaning. It's like listening to a whole sentence at once to understand context.
            </div>
        </div>
        
        <div class="arrow">↓</div>

        <div class="transformer-component" id="add-norm-1">
            <h4>Add &amp; Norm</h4>
            <div class="popup">
                <strong>Residual Connection ("Add"):</strong> A shortcut that adds the original input to the output of the attention step. This ensures that the model doesn't "forget" the original information. It's crucial for training deep networks.
                <br/><br/>
                <strong>Layer Normalization ("Norm"):</strong> A cleanup step that stabilizes the numbers, ensuring the process runs smoothly without an explosion of values.
            </div>
        </div>

        <div class="arrow">↓</div>

        <div class="transformer-component" id="ffn">
            <h4>Feed-Forward Network</h4>
            <div class="popup">
                <strong>The "Processing Unit":</strong> After gathering context, this network "thinks" about the information. It's a standard neural network that finds deeper patterns and transforms the data into a more refined state.
            </div>
        </div>

        <div class="arrow">↓</div>

        <div class="transformer-component" id="add-norm-2">
            <h4>Add &amp; Norm</h4>
             <div class="popup">
                <strong>Add & Norm:</strong> The same process as before. A residual connection adds the output of the previous "Add & Norm" step, and Layer Normalization cleans up the result before sending it on.
            </div>
        </div>

        <div class="arrow">↓</div>

        <div class="transformer-component" id="output">
            <h4>Output</h4>
            <div class="popup">
                <strong>Final Result:</strong> The refined vectors are sent to the next Transformer block for more processing. If this is the last block, the output is used to predict the next word in the sentence.
            </div>
        </div>
        
    </div>
</div> 